{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WK6djukC6uSq"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUCfANv96z2Z",
    "outputId": "9a5892a8-0cae-4062-ea05-eceeda9efaf6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghodi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ghodi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision import transforms as T\n",
    "\n",
    "class CustomCSVDetectionDataset(Dataset):\n",
    "    def __init__(self, csv_file, images_dir, transforms=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.images_dir = images_dir\n",
    "        self.transforms = transforms\n",
    "        self.image_ids = self.df['image_name'].unique()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        records = self.df[self.df['image_name'] == image_id]\n",
    "\n",
    "        image = Image.open(os.path.join(self.images_dir, image_id)).convert(\"RGB\")\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        for _, row in records.iterrows():\n",
    "            xmin = row['bbox_x']\n",
    "            ymin = row['bbox_y']\n",
    "            xmax = xmin + row['bbox_width']\n",
    "            ymax = ymin + row['bbox_height']\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "            labels.append(1 if row['label_name'] == 'Marine Animal' else 2)\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        image_id = torch.tensor([idx])\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "\n",
    "        # Convert image to tensor if no transformations are applied\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        else:\n",
    "            image = T.ToTensor()(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "# Define paths\n",
    "csv_file = 'Dataset7.0/train/annotations/train_labels.csv'\n",
    "images_dir = 'Dataset7.0/train/images'\n",
    "\n",
    "# Create dataset and dataloaders without transformations\n",
    "dataset = CustomCSVDetectionDataset(csv_file, images_dir, transforms=None)\n",
    "\n",
    "# DataLoader setup\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
    "\n",
    "def get_model(num_classes):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "# Initialize the model\n",
    "model = get_model(num_classes=3)  # 2 classes (marine animal, trash) + background\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "import torch.optim as optim\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "it-USXsy639a",
    "outputId": "6756ad17-773a-4e83-aa6f-4094ffd22ce3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghodi\\AppData\\Local\\Temp\\ipykernel_1520\\1859032435.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from model/model_weights_epoch_43.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# Define the path to your model weights\n",
    "model_path = 'model/model_weights_epoch_43.pth'\n",
    "\n",
    "# Initialize the model\n",
    "def get_model(num_classes):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "# Create an instance of the model\n",
    "model = get_model(num_classes=3)  # Replace 3 with the number of classes in your dataset\n",
    "\n",
    "# Load the model weights onto CPU\n",
    "device = torch.device('cpu')  # Specify the device (CPU in this case)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Print a message indicating successful loading\n",
    "print(f\"Model loaded from {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QEWX1krr69pH"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Zee1wzNm6-b5"
   },
   "outputs": [],
   "source": [
    "class_colors = {\n",
    "    1: (255, 165, 0),  # Marine Animal - Orange\n",
    "    2: (255, 255, 0)   # Trash - Yellow\n",
    "}\n",
    "\n",
    "class_names = {\n",
    "    1: 'Marine Animal',\n",
    "    2: 'Trash'\n",
    "}\n",
    "\n",
    "label_to_int = {\n",
    "    'Marine Animal': 1,\n",
    "    'Trash': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OqzEEvLr7AfK"
   },
   "outputs": [],
   "source": [
    "def visualize_predictions(image, boxes, labels, scores, threshold=0.5):\n",
    "    image = np.array(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score > threshold:\n",
    "            box = box.astype(np.int32)\n",
    "            color = class_colors.get(label, (255, 255, 255))\n",
    "            label_name = class_names.get(label, 'Unknown')\n",
    "\n",
    "            cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), color, 2)\n",
    "            cv2.putText(image, f\"{label_name}: {score:.2f}\", (box[0], box[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "UXn2r2V47Jpa",
    "outputId": "9ee4caf0-747c-4a49-99ea-d54da4f97097"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghodi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Ghodi\\AppData\\Local\\Temp\\ipykernel_1520\\925296329.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "2024-11-18 11:42:19.711 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 11:42:20.093 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Ghodi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-11-18 11:42:20.095 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 11:42:20.096 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 11:42:20.097 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 11:42:20.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 11:42:20.100 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 11:42:20.102 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "import torchvision\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "    num_classes = 3  # Replace with the number of classes in your dataset\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # Load the model weights onto CPU\n",
    "    device = torch.device('cpu')  # Use CPU for deployment\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load the model\n",
    "model_path = 'model/model_weights_epoch_43.pth'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Function to preprocess and predict\n",
    "def predict_image(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_tensor = ToTensor()(image).unsqueeze(0)  # Convert to tensor\n",
    "    with torch.no_grad():\n",
    "        predictions = model(image_tensor)\n",
    "    return predictions\n",
    "\n",
    "# Streamlit app\n",
    "def main():\n",
    "    st.title('Marine Animals and Trash Detection')\n",
    "\n",
    "    uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        # Read the uploaded image\n",
    "        image = cv2.imdecode(np.frombuffer(uploaded_file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "\n",
    "        # Perform prediction\n",
    "        predictions = predict_image(image)\n",
    "\n",
    "        # Example: Extract bounding boxes, labels, and scores from predictions\n",
    "        pred_boxes = predictions[0]['boxes'].cpu().numpy()\n",
    "        pred_labels = predictions[0]['labels'].cpu().numpy()\n",
    "        pred_scores = predictions[0]['scores'].cpu().numpy()\n",
    "\n",
    "        # Display the image with predictions\n",
    "        st.image(image, channels=\"RGB\", caption=\"Uploaded Image\")\n",
    "\n",
    "        # Visualize predictions on the image\n",
    "        for box, label, score in zip(pred_boxes, pred_labels, pred_scores):\n",
    "            if score > 0.5:  # Adjust the threshold as needed\n",
    "                st.markdown(f\"**Label:** {label}, **Score:** {score:.2f}\")\n",
    "                image = cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (255, 0, 0), 2)\n",
    "\n",
    "        # Display the annotated image\n",
    "        st.image(image, channels=\"RGB\", caption=\"Annotated Image with Predictions\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
